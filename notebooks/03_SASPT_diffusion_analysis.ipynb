{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set user-defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set user-defined parameters for analysis ###\n",
    "\n",
    "# Point the settings file to JSON file with analysis parameters.\n",
    "# This path (and others in this notebook) can be relative or absolute.\n",
    "settings_file = '../data/analysis_settings/Fig3sup4_SASPT_MSD_analysis.json'\n",
    "\n",
    "# Set plotting and figure saving params\n",
    "plot_figs = True\n",
    "plot_all_tracks = False # warning - takes forever!\n",
    "save_figs = True # Save output figures\n",
    "save_data = True # Save filtered tracks to see which ones were identified as correlated.\n",
    "\n",
    "split_by_color = False # Analyze diffusion of dyes in two channels separately if True\n",
    "\n",
    "plot_settings = '../src/plotting_settings.py' # File containing matplotlib settings\n",
    "save_dir_reports = '../reports/figures' # Base directory for saving figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load modules ###\n",
    "\n",
    "# Uncomment the following two lines for debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import general Python modules\n",
    "import os, sys, inspect\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import relevant parts of the SASPT module (see ref in manuscript)\n",
    "from saspt import StateArray, RBME, StateArrayDataset, normalize_2d\n",
    "\n",
    "# Add source code directory (src) to path to enable user module import\n",
    "module_dir = '../src'\n",
    "os.sys.path.insert(0, module_dir)\n",
    "\n",
    "# Import user modules from source code directory\n",
    "import parse_trackmate as pt\n",
    "import correlation_analysis as corr\n",
    "import diffusion as dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the JSON settings file that specifies analysis details ###\n",
    "# Note: for diffusion analysis, the JSON settings file must contain\n",
    "# the following keys: 'diff_dim', 'min_averages_for_msd', 'dc_fit_nframes',\n",
    "# and \"frame_interval_sec\" (the latter is in seconds)\n",
    "\n",
    "conditions, params = corr.read_analysis_params(settings_file, \n",
    "                                               save_dir_reports, \n",
    "                                               print_summary=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up figure save directories and load plotting style ###\n",
    "\n",
    "save_dir = params['save_dir']\n",
    "save_dir_data = params['save_dir_data']\n",
    "\n",
    "# Prepare directory for saving CSV exports of trajectories\n",
    "save_dir_csv = os.path.join(save_dir_data, 'csv_for_saspt')\n",
    "if not os.path.exists(save_dir_csv):\n",
    "        os.makedirs(save_dir_csv)\n",
    "\n",
    "if save_figs: # Save figure files\n",
    "    %matplotlib\n",
    "    %run $plot_settings save_large\n",
    "    \n",
    "    # Make directories for saving figures\n",
    "    dir_sum_figs = os.path.join(save_dir, 'summary_figures')\n",
    "    dir_examples = os.path.join(save_dir, 'examples')\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    if not os.path.exists(dir_sum_figs):\n",
    "        os.makedirs(dir_sum_figs)\n",
    "    if not os.path.exists(dir_examples):\n",
    "        os.makedirs(dir_examples)    \n",
    "else: # Plot interactively\n",
    "    %matplotlib\n",
    "    %run $plot_settings plot_only\n",
    "    \n",
    "if save_data: # Save filtered TrackMate trajectories\n",
    "    if not os.path.exists(save_dir_data):\n",
    "        os.makedirs(save_dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse track data from TrackMate xml files into Pandas dataframes ###\n",
    "\n",
    "data_parsed = {} # List of dataframes, one dataframe per condition\n",
    "for condition in conditions:\n",
    "    print(\"Now processing condition: \" + condition)\n",
    "    data_parsed[condition] = pt.read_2color_data(conditions[condition],\n",
    "                                    do_int_analysis=params['do_int_analysis'],\n",
    "                                    int_settings=params['int_settings'])\n",
    "print('Done parsing. Data loading is now complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning of SASPT analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of trajectories pooled by condition (e.g. treatment or construct type).\n",
    "# Export all trajectories as CSV files that can be read by SASPT\n",
    "\n",
    "# Create organizer CSV file to keep track of CSV files storing individual trajectories\n",
    "csv_organizer_base_name = os.path.basename(settings_file).split('.')[0]\n",
    "csv_organizer_filename = 'org_'+csv_organizer_base_name+'.csv'\n",
    "csv_organizer_path = os.path.join(save_dir_csv, csv_organizer_filename)\n",
    "\n",
    "# Save trajectories as CSV files with columns \"trajectory\", \"frame\", \"x\", and \"y\".\n",
    "# These files can then be directly read by the saspt module.\n",
    "csv_paths = []\n",
    "csv_conditions =[]\n",
    "for condition in data_parsed:\n",
    "    data = data_parsed[condition]\n",
    "    for row in data.itertuples(index=False):\n",
    "        filename_source = row[0]\n",
    "        data_to_save = row[4][['track_ID','t','x','y']]\n",
    "        #rename columns as needed\n",
    "        df = data_to_save.rename(columns={\"track_ID\": \"trajectory\", \"t\": \"frame\"})\n",
    "        \n",
    "        csv_filename = filename_source + '.csv'\n",
    "        csv_path = os.path.join(save_dir_csv,csv_filename)\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        # Append color to the condition if needed\n",
    "        if split_by_color:\n",
    "            color = row[2]\n",
    "            csv_condition = condition + '_' + color\n",
    "        else:\n",
    "            csv_condition = condition\n",
    "        csv_paths.append(csv_path)\n",
    "        csv_conditions.append(csv_condition)\n",
    "\n",
    "csv_organizer = pd.DataFrame({\"filepath\":csv_paths, \"condition\":csv_conditions})\n",
    "csv_organizer.to_csv(csv_organizer_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state array dataset (all trajectories from all conditions)\n",
    "\n",
    "paths = pd.read_csv(csv_organizer_path)\n",
    "#print(paths) # Uncomment for debugging\n",
    "num_workers = os.cpu_count()\n",
    "print(num_workers)\n",
    "\n",
    "print(params['raw_json']['frame_interval_sec'])\n",
    "\n",
    "# Load settings form params file if possible:\n",
    "try:\n",
    "    frame_interval = params['raw_json']['frame_interval_sec']\n",
    "except:\n",
    "    print('Frame interval not loaded, reverting to defaults')\n",
    "    frame_interval = 0.06\n",
    "try:\n",
    "    focal_depth = params['raw_json']['focal_depth_um']\n",
    "except:\n",
    "    print('Focal depth not loaded, reverting to defaults')\n",
    "    focal_depth = 0.2\n",
    "\n",
    "settings = dict(\n",
    "    likelihood_type = RBME,\n",
    "    pixel_size_um = 1,\n",
    "    frame_interval = frame_interval,\n",
    "    focal_depth = focal_depth,\n",
    "    diff_coefs = np.logspace(-2.0,0.0,num=100),\n",
    "    loc_errors = np.linspace(0.0, 0.05, num=20),\n",
    "    path_col = 'filepath',\n",
    "    condition_col = 'condition',\n",
    "    progress_bar = True,\n",
    "    num_workers = num_workers,\n",
    ")\n",
    "\n",
    "SAD = StateArrayDataset.from_kwargs(paths, **settings)\n",
    "print(SAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate posterior heat maps and line plots, sorted by file and condition.\n",
    "# Takes a while for large datasets.\n",
    "\n",
    "SAD.posterior_heat_map(os.path.join(dir_sum_figs,'posterior_heat_map.pdf'))\n",
    "SAD.posterior_line_plot(os.path.join(dir_sum_figs,'posterior_line_plot.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all files in each condition\n",
    "\n",
    "posterior_occs, condition_names = SAD.infer_posterior_by_condition('condition')\n",
    "print(posterior_occs.shape)\n",
    "print(condition_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior occupations for aggregated trajectories\n",
    "\n",
    "limit_conditions_to_plot = None\n",
    "# Optionally, select a subset of conditions for a plot below:\n",
    "#limit_conditions_to_plot = ['HaloTag-1x_C1', 'HaloTag-GST_C1','EndoIRE1-NoStress_C1','EndoIRE1_4h-Tm_C1']\n",
    "\n",
    "posterior_occs = normalize_2d(posterior_occs, axis=1)\n",
    "diff_coefs = SAD.likelihood.diff_coefs\n",
    "for c in range(posterior_occs.shape[0]):\n",
    "    if limit_conditions_to_plot is None or condition_names[c] in limit_conditions_to_plot:\n",
    "        plt.plot(diff_coefs, posterior_occs[c,:], label=condition_names[c])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Diff. coef. ($\\mu$m$^{2}$ s$^{-1}$)')\n",
    "plt.ylabel('Mean posterior occupation')\n",
    "plt.ylim((0, plt.ylim()[1]))\n",
    "\n",
    "# Custom x-limits if needed\n",
    "plt.xlim((1e-4, plt.xlim()[1]))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save figures and statistics if needed\n",
    "if save_figs:\n",
    "    fig_name = 'Aggregated_posterior_occupations_by_condition'\n",
    "    full_fig_path = os.path.join(dir_sum_figs, fig_name+'.pdf')\n",
    "    plt.savefig(full_fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fraction of trajectories within a specific range of diff. coeff.:\n",
    "occupations = SAD.marginal_posterior_occs_dataframe\n",
    "#print(occupations)\n",
    "diff_cutoff = 0.17\n",
    "cond = occupations['diff_coef'] < diff_cutoff\n",
    "temp = occupations.loc[cond].groupby('filepath')['posterior_occupation'].sum().reset_index()\n",
    "temp.rename(columns={\"posterior_occupation\": \"fraction_cutoff\"}, inplace=True)\n",
    "grouped = occupations.groupby('filepath').first().reset_index()\n",
    "result = grouped.merge(temp, how='inner',on='filepath')\n",
    "\n",
    "#by_cond = result.loc[cond].groupby('condition')['fraction_cutoff'].mean()\n",
    "by_cond = result.groupby('condition')['fraction_cutoff'].agg(['mean', 'count', 'std', 'sem'])\n",
    "print(by_cond)\n",
    "if save_data:\n",
    "    data_file_name = 'Fraction_of_trajectories_below_diff_'+str(diff_cutoff)\n",
    "    full_data_file_path = os.path.join(dir_sum_figs, data_file_name+'.csv')\n",
    "    by_cond.to_csv(full_data_file_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean diffusion coefficients per condition:\n",
    "\n",
    "temp = occupations.copy()\n",
    "# To get the mean diffusion coefficient in a movie, multiply each value by its posterior occupation\n",
    "temp['weighed_dc'] = temp['diff_coef'] * temp ['posterior_occupation']\n",
    "temp2 = temp.groupby('filepath')['weighed_dc'].sum().reset_index()\n",
    "temp2.rename(columns={\"weighed_dc\": \"mean_dc\"}, inplace=True)\n",
    "grouped = occupations.groupby('filepath').first().reset_index()\n",
    "result = grouped.merge(temp2, how='inner',on='filepath')\n",
    "\n",
    "by_cond = result.groupby('condition')['mean_dc'].agg(['mean', 'count', 'std', 'sem'])\n",
    "print(by_cond)\n",
    "\n",
    "if save_data:\n",
    "    data_file_name = 'Mean_diffusion_coeff_by_condition'\n",
    "    full_data_file_path = os.path.join(dir_sum_figs, data_file_name+'.csv')\n",
    "    by_cond.to_csv(full_data_file_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pairwise Monte-Carlo permutation tests to check for differences between conditions\n",
    "test_results = corr.pairwise_perm_tests(result, 'mean_dc', 'condition', num_iter=1000)\n",
    "\n",
    "# Save the statistics results\n",
    "if save_data:\n",
    "    data_file_name = 'Pairwise_correlations_diff_const'\n",
    "    full_data_file_path = os.path.join(dir_sum_figs, data_file_name+'.txt')\n",
    "    with open(full_data_file_path, \"w\") as f:\n",
    "        f.writelines(test_results)\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this block to check the sample dataset.\n",
    "# Use this only to troubleshoot your saspt module's installation\n",
    "\n",
    "\"\"\"\n",
    "from saspt import sample_detections\n",
    "\n",
    "detections = sample_detections()\n",
    "\n",
    "settings = dict(\n",
    "    likelihood_type = RBME,\n",
    "    pixel_size_um = 0.122,\n",
    "    frame_interval = 0.01,\n",
    "    focal_depth = 0.7,\n",
    "    progress_bar = True,\n",
    ")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
