{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set user-defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set user-defined parameters for analysis ###\n",
    "\n",
    "# Point the settings file to JSON file with analysis parameters.\n",
    "# This path (and others in this notebook) can be relative or absolute.\n",
    "#settings_file = '../data/analysis_settings/2021_12_03_reviewerExpts.json'\n",
    "settings_file = '../data/analysis_settings/FigXX_HaloTagControls_Diffusion_test.json'\n",
    "\n",
    "# Set plotting and figure saving params\n",
    "plot_figs = True\n",
    "plot_all_tracks = False # warning - takes forever!\n",
    "save_figs = False # Save output figures\n",
    "save_data = True # Save filtered tracks to see which ones were identified as correlated.\n",
    "\n",
    "plot_settings = '../src/plotting_settings.py' # File containing matplotlib settings\n",
    "save_dir_reports = '../reports/figures' # Base directory for saving figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load modules ###\n",
    "\n",
    "# Uncomment the following two lines for debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import general Python modules\n",
    "import os, sys, inspect\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Add source code directory (src) to path to enable user module import\n",
    "module_dir = '../src'\n",
    "os.sys.path.insert(0, module_dir)\n",
    "\n",
    "# Import user modules from source code directory\n",
    "import parse_trackmate as pt\n",
    "import correlation_analysis as corr\n",
    "import diffusion as dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the JSON settings file that specifies analysis details ###\n",
    "# Note: for diffusion analysis, the JSON settings file must contain\n",
    "# the following keys: 'diff_dim', 'min_averages_for_msd', 'dc_fit_nframes',\n",
    "# and \"frame_interval_sec\" (the latter is in seconds)\n",
    "\n",
    "conditions, params = corr.read_analysis_params(settings_file, \n",
    "                                               save_dir_reports, \n",
    "                                               print_summary=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up figure save directories and load plotting style ###\n",
    "\n",
    "save_dir = params['save_dir']\n",
    "save_dir_data = params['save_dir_data']\n",
    "\n",
    "if save_figs: # Save figure files\n",
    "    %matplotlib\n",
    "    %run $plot_settings save_large\n",
    "    \n",
    "    # Make directories for saving figures\n",
    "    dir_sum_figs = os.path.join(save_dir, 'summary_figures')\n",
    "    dir_examples = os.path.join(save_dir, 'examples') \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    if not os.path.exists(dir_sum_figs):\n",
    "        os.makedirs(dir_sum_figs)\n",
    "    if not os.path.exists(dir_examples):\n",
    "        os.makedirs(dir_examples)    \n",
    "else: # Plot interactively\n",
    "    %matplotlib\n",
    "    %run $plot_settings plot_only\n",
    "    \n",
    "if save_data: # Save filtered TrackMate trajectories\n",
    "    if not os.path.exists(save_dir_data):\n",
    "        os.makedirs(save_dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse track data from TrackMate xml files into Pandas dataframes ###\n",
    "\n",
    "data_parsed = {} # List of dataframes, one dataframe per condition\n",
    "for condition in conditions:\n",
    "    print(\"Now processing condition: \" + condition)\n",
    "    data_parsed[condition] = pt.read_2color_data(conditions[condition],\n",
    "                                    do_int_analysis=params['do_int_analysis'],\n",
    "                                    int_settings=params['int_settings'])\n",
    "print('Done parsing. Data loading is now complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning of SASPT analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_parsed['HaloTag-1x'].loc[0,'parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saspt import sample_detections, StateArray, RBME\n",
    "\n",
    "#test_df = data_parsed['HaloTag-1x'].loc[0,'parsed']\n",
    "#test_df = data_parsed['HaloTag-GST'].loc[0,'parsed']\n",
    "#test_df = data_parsed['EndoIRE1-NoStress'].loc[0,'parsed']\n",
    "test_df = data_parsed['EndoIRE1_4h-Tm'].loc[1,'parsed']\n",
    "#df_new = test_df.rename(columns={\"track_ID\": \"TRACK\", \"t\": \"FRAME\", 'x':\"PX\", \"y\":\"PY\"})\n",
    "df_new = test_df.rename(columns={\"track_ID\": \"trajectory\", \"t\": \"frame\"})\n",
    "\n",
    "\n",
    "print(df_new)\n",
    "\n",
    "detections = df_new\n",
    "settings = dict(\n",
    "    likelihood_type = RBME,\n",
    "    pixel_size_um = 1,\n",
    "    frame_interval = 0.06,\n",
    "    focal_depth = 1,\n",
    "    progress_bar = True,\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "detections = sample_detections()\n",
    "\n",
    "settings = dict(\n",
    "    likelihood_type = RBME,\n",
    "    pixel_size_um = 0.122,\n",
    "    frame_interval = 0.01,\n",
    "    focal_depth = 0.7,\n",
    "    progress_bar = True,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "SA = StateArray.from_detections(detections, **settings)\n",
    "\n",
    "print(SA)\n",
    "\n",
    "#naive_occs = SA.naive_occs\n",
    "#posterior_occs = SA.posterior_occs\n",
    "\n",
    "SA.plot_occupations('test.png')\n",
    "\n",
    "#occupations = SA.occupations_dataframe\n",
    "#print(occupations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of trajectories pooled by condition\n",
    "# Export all trajectories as CSV files that can be read by SASPT\n",
    "\n",
    "csv_organizer_filename = 'organizer.csv'\n",
    "save_dir_csv = os.path.join(save_dir_data, 'csv_for_saspt')\n",
    "if not os.path.exists(save_dir_csv):\n",
    "        os.makedirs(save_dir_csv)\n",
    "csv_organizer_path = os.path.join(save_dir_csv, csv_organizer_filename)\n",
    "\n",
    "csv_paths = []\n",
    "csv_conditions =[]\n",
    "for condition in data_parsed:\n",
    "    data = data_parsed[condition]\n",
    "    for row in data.itertuples(index=False):\n",
    "        filename_source = row[0]\n",
    "        color = row[2]\n",
    "        data_to_save = row[4][['track_ID','t','x','y']]\n",
    "        #rename columns as needed\n",
    "        df = data_to_save.rename(columns={\"track_ID\": \"trajectory\", \"t\": \"frame\"})\n",
    "        \n",
    "        csv_filename = filename_source + '.csv'\n",
    "        csv_path = os.path.join(save_dir_csv,csv_filename)\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        csv_condition = condition + '_' + color\n",
    "        csv_paths.append(csv_path)\n",
    "        csv_conditions.append(csv_condition)\n",
    "\n",
    "csv_organizer = pd.DataFrame({\"filepath\":csv_paths, \"condition\":csv_conditions})\n",
    "csv_organizer.to_csv(csv_organizer_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = pd.read_csv(csv_organizer_path)\n",
    "print(paths)\n",
    "\n",
    "settings = dict(\n",
    "    likelihood_type = RBME,\n",
    "    pixel_size_um = 1,\n",
    "    frame_interval = 0.06,\n",
    "    focal_depth = 0.7,\n",
    "    path_col = 'filepath',\n",
    "    condition_col = 'condition',\n",
    "    progress_bar = True,\n",
    "    num_workers = 4,\n",
    ")\n",
    "\n",
    "from saspt import StateArrayDataset\n",
    "SAD = StateArrayDataset.from_kwargs(paths, **settings)\n",
    "\n",
    "print(SAD)\n",
    "\n",
    "SAD.posterior_heat_map('posterior_heat_map.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAD.posterior_line_plot('posterior_line_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_occs, condition_names = SAD.infer_posterior_by_condition('condition')\n",
    "print(posterior_occs.shape)\n",
    "print(condition_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditions_to_plot = ['EndoIRE1-NoStress_C1','EndoIRE1_4h-Tm_C1', 'HaloTag-1x_C1', 'HaloTag-GST_C1']\n",
    "#conditions_to_plot = ['HaloTag-1x_C1', 'HaloTag-GST_C1', 'HaloTag-2x-tandem_C1', 'HaloTag_4x_C1']\n",
    "conditions_to_plot = ['HaloTag-1x_C1', 'HaloTag-GST_C1','EndoIRE1-NoStress_C1','EndoIRE1_4h-Tm_C1']\n",
    "\n",
    "from saspt import normalize_2d\n",
    "posterior_occs = normalize_2d(posterior_occs, axis=1)\n",
    "diff_coefs = SAD.likelihood.diff_coefs\n",
    "for c in range(posterior_occs.shape[0]):\n",
    "    if condition_names[c] in conditions_to_plot:\n",
    "        plt.plot(diff_coefs, posterior_occs[c,:], label=condition_names[c])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Diff. coef. ($\\mu$m$^{2}$ s$^{-1}$)')\n",
    "plt.ylabel('Mean posterior occupation')\n",
    "plt.ylim((0, plt.ylim()[1]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
