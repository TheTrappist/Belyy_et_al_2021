{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set user-defined parameters for analysis ###\n",
    "settings_file = '../data/processed/vVB_210528_TrackMateOut/Analysis_settings/20210528_msd_analysis.json'\n",
    "\n",
    "# Plotting and figure saving params\n",
    "plot_figs = True\n",
    "plot_all_tracks = False # Don't do this one \n",
    "save_figs = False # Code for saving data still needs work. I've just been manually saving them as they pop up.\n",
    "save_data = False\n",
    "manual_correlation_override = False\n",
    "\n",
    "plot_settings = '../src/plotting_settings.py'\n",
    "save_dir_reports = '../reports/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, inspect\n",
    "\n",
    "# Add source code directory to path to enable module import\n",
    "module_dir = '../src'\n",
    "os.sys.path.insert(0, module_dir)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import random\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import parse_trackmate as pt\n",
    "import diffusion as dif\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the json settings file\n",
    "\n",
    "with open(settings_file) as fd:\n",
    "    json_data = json.load(fd)\n",
    "    \n",
    "base_dir = os.path.split(settings_file)[0]\n",
    "base_dir = os.path.abspath(base_dir) # Because paths are relative in the settings\n",
    "\n",
    "# Build lists of folders containing tracks for each condition\n",
    "conditions = {}\n",
    "for condition, folders in json_data['conditions'].items():\n",
    "    if type(folders) is not list: folders = [folders]\n",
    "    paths = []\n",
    "    for folder in folders:\n",
    "        full_path = os.path.join(base_dir, folder)\n",
    "        paths = paths + [os.path.normpath(full_path)]\n",
    "    conditions[condition] = paths\n",
    "\n",
    "# Build paths for output files\n",
    "save_dir = os.path.join(save_dir_reports, json_data['save_dir_reports'])\n",
    "save_dir = os.path.normpath(save_dir)\n",
    "save_dir_data = os.path.join(base_dir, json_data['save_dir_filt_data'])\n",
    "save_dir_data = os.path.normpath(save_dir_data)\n",
    "\n",
    "# Load the analysis settings\n",
    "diff_dim = json_data['diff_dim']\n",
    "min_averages_for_msd = json_data['min_averages_for_msd']\n",
    "dc_fit_nframes = json_data['dc_fit_nframes']\n",
    "\n",
    "print(diff_dim, min_averages_for_msd, dc_fit_nframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure save dirs and load plotting style\n",
    "if save_figs:\n",
    "    %matplotlib\n",
    "    %run $plot_settings save_large\n",
    "    \n",
    "    # Make directories for saving figures\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    dir_sum_figs = os.path.join(save_dir, 'summary_figures')\n",
    "    if not os.path.exists(dir_sum_figs):\n",
    "        os.makedirs(dir_sum_figs)\n",
    "    \n",
    "    dir_examples = os.path.join(save_dir, 'examples')\n",
    "    if not os.path.exists(dir_examples):\n",
    "        os.makedirs(dir_examples)\n",
    "\n",
    "else:\n",
    "    %matplotlib\n",
    "    %run $plot_settings plot_only\n",
    "    \n",
    "if save_data:\n",
    "    if not os.path.exists(save_dir_data):\n",
    "        os.makedirs(save_dir_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up directories/locations for your movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note: </b>If you get a '.str' type of error below, make sure that there are no typos when specifying directories in the .json settings file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse track data from TrackMate xml files into Pandas dataframe ###\n",
    "\n",
    "def read_data(data_dirs):\n",
    "    if type(data_dirs) is not list: data_dirs = [data_dirs] # for a single directory\n",
    "    data_files, file_names = [],[]\n",
    "    for data_dir in data_dirs:\n",
    "        curr_files = sorted(glob.glob(os.path.join(data_dir,'**/*.xml'), recursive=True))\n",
    "        stripped_names = [os.path.basename(f) for f in curr_files]\n",
    "        curr_names = [os.path.splitext(fn)[0] for fn in stripped_names]\n",
    "        data_files = data_files + curr_files\n",
    "        file_names = file_names + curr_names\n",
    "    data = pd.DataFrame({'file_name' : file_names, 'file_path' : data_files})\n",
    "    data['color'] = data['file_name'].str.slice(0,2)\n",
    "    data['movie_ID'] = data['file_name'].str.slice(3,)\n",
    "    \n",
    "    # Parse data\n",
    "    data['parsed'] = \"\"\n",
    "    spot_num_attr = []\n",
    "    '''if do_int_analysis:\n",
    "        if int_settings[\"bkgnd_correction_type\"] == \"local\":\n",
    "            spot_num_attr = ['INT_C1_CORR_LOC', 'INT_C2_CORR_LOC']\n",
    "        elif int_settings[\"bkgnd_correction_type\"] == \"global\":\n",
    "            spot_num_attr = ['INT_GLOBAL_C1', 'INT_GLOBAL_C2']\n",
    "        else: # load all\n",
    "            spot_num_attr = ['INT_C1_CORR_LOC', 'INT_C2_CORR_LOC', \n",
    "                             'INT_GLOBAL_C1', 'INT_GLOBAL_C2']'''\n",
    "    for idx in data.index:\n",
    "        a,_,_ = pt.parse_trackmate_file(data['file_path'].loc[idx],\n",
    "                                       spot_num_attr=spot_num_attr)\n",
    "        data.at[idx, 'parsed'] = a\n",
    "    \n",
    "    return data\n",
    "\n",
    "data_parsed = {}\n",
    "for condition in conditions:\n",
    "    print(\"Now processing condition: \" + condition)\n",
    "    data_parsed[condition] = read_data(conditions[condition])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function that can take in the movies and return track trajectories in the form of coordinates within\n",
    "# pandas dataframe corresponding to each channel.\n",
    "\n",
    "def get_movie_data_both_channels(data, movie_ID):\n",
    "    print(\"Processing movie:\", movie_ID)\n",
    "    \n",
    "    # Get indices of the movies of both colors, denoted by C1 and C2\n",
    "    movie_idx = data['movie_ID'] == movie_ID\n",
    "    idx_C1 = data.index[movie_idx & (data['color'] == 'C1')]\n",
    "    idx_C2 = data.index[movie_idx & (data['color'] == 'C2')]\n",
    "    \n",
    "    # Locate data for each color of the current movie\n",
    "    df_C1 = data.loc[idx_C1, 'parsed'].iat[0]\n",
    "    df_C2 = data.loc[idx_C2, 'parsed'].iat[0]\n",
    "    \n",
    "    # Locate corresponding file names and paths\n",
    "    filename_C1 = data.loc[idx_C1, 'file_name'].iat[0]\n",
    "    file_path_C1 = data.loc[idx_C1, 'file_path'].iat[0]\n",
    "    filename_C2 = data.loc[idx_C2, 'file_name'].iat[0]\n",
    "    file_path_C2 = data.loc[idx_C2, 'file_path'].iat[0]\n",
    "    \n",
    "    names_paths = {'name_C1' : filename_C1, 'path_C1' : file_path_C1,\n",
    "                    'name_C2' : filename_C1, 'path_C2' : file_path_C2}\n",
    "    \n",
    "    return df_C1, df_C2, names_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pool the tracks in a channel\n",
    "frame_interval = 0.05 # Change this according to needs\n",
    "def pool_tracks(channel_dat):\n",
    "    channel_tracks = []\n",
    "    cols = ['x', 'y', 't']\n",
    "    for i in range(0, max(channel_dat['track_ID'])):\n",
    "        track = np.array(channel_dat[channel_dat['track_ID'] == i][cols])\n",
    "        channel_tracks.append(track)\n",
    "    return channel_tracks\n",
    "\n",
    "# Define function to calculate MSD for each track and fit to a\n",
    "# diffusion coefficient.\n",
    "\n",
    "def calculate_msd(tracks, frame_interval):\n",
    "    \n",
    "    d = []\n",
    "    for track in tracks:\n",
    "        len_track = np.shape(track)[0]\n",
    "        if len_track < (dc_fit_nframes * min_averages_for_msd):\n",
    "            continue\n",
    "\n",
    "        # Break up the track into sub-trajectories for MSD calc'n\n",
    "        track_chunks = []\n",
    "        n_chunks = int(np.floor(len_track / dc_fit_nframes))\n",
    "        for i in range(n_chunks):\n",
    "            start_slice = i * dc_fit_nframes\n",
    "            end_slice = start_slice + dc_fit_nframes\n",
    "            chunk = track[start_slice:end_slice, :]\n",
    "            track_chunks.append(chunk)\n",
    "\n",
    "        # Get the data\n",
    "        t_dsq, msd_data = dif.calc_msd(track_chunks, frame_interval)\n",
    "\n",
    "        time, mean_dsq, std_dsq, sterr_dsq = msd_data\n",
    "\n",
    "        # Fit to get the diffusion coefficient\n",
    "        fit_params = dif.fit_diffusion_const(msd_data, dim = diff_dim,\n",
    "                                            nframes = dc_fit_nframes)\n",
    "\n",
    "        d.append({'Track_ID':i, 'Diff_const':fit_params['dc']})\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(d)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for calculating the MSD for particles in \n",
    "# each channel for each movie in each condition\n",
    "\n",
    "def get_condition_msd(all_data, condition):\n",
    "    data = all_data[condition]\n",
    "    \n",
    "    condition_msd = []\n",
    "    movie_counter = 1\n",
    "    for movie in data:\n",
    "        print('Now processing movie:', str(movie_counter))\n",
    "        movie_counter += 1\n",
    "        movie_msd = []\n",
    "        channel_counter = 1\n",
    "        for channel in movie:\n",
    "            print('Now processing channel:', str(channel_counter))\n",
    "            channel_counter += 1\n",
    "            channel_tracks = pool_tracks(channel)\n",
    "            msd_dat = calculate_msd(channel_tracks, frame_interval)\n",
    "            movie_msd.append(msd_dat)\n",
    "        condition_msd.append(movie_msd)\n",
    "    print('Processing finished!')\n",
    "    return condition_msd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting and MSD calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data in an accessible manner - this will be a dictionary that has the condition as keys. The \n",
    "# values are lists that contains coordinate information for each channel in the movie.\n",
    "all_dat = dict()\n",
    "for condition in conditions:\n",
    "    all_dat[condition] = list()\n",
    "    condition_dat = data_parsed[condition]\n",
    "    for movie_id in condition_dat['movie_ID'].unique():\n",
    "        df_C1, df_C2, names_paths = get_movie_data_both_channels(condition_dat,\n",
    "                                                                movie_id)\n",
    "        all_dat[condition].append([df_C1, df_C2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the code block above, this code block will give you a dictionary that uses the condition as the keys.\n",
    "# The values will be a list containing the MSDs of particles associated with a treatment condition. This code block\n",
    "# takes a while, especially if you are pooling datasets.\n",
    "\n",
    "condition_msds = dict()\n",
    "for condition in conditions:\n",
    "    print('Now processing:', condition)\n",
    "    condition_msds[condition] = get_condition_msd(all_dat, condition)\n",
    "print('Really finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appends the \"condition\" column to the current dataframe to allow for subsequent subsetting/slicing of data\n",
    "def append_condition(condition_channel_df, condition, channel):\n",
    "    condition_list = list()\n",
    "    channel_list = list()\n",
    "    for i in range(0, len(condition_channel_df)):\n",
    "        condition_list.append(condition)\n",
    "        if channel == 0:\n",
    "            channel_list.append('Green')\n",
    "        elif channel == 1:\n",
    "            channel_list.append('Red')\n",
    "    condition_channel_df['Condition'] = condition_list\n",
    "    condition_channel_df['Channel'] = channel_list\n",
    "    return condition_channel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional code block for cleaner labels. Used for plotting\n",
    "conditions_1 = ['1x Halo', '2x Halo', 'No Stress', '0.025 mM PA', '0.10 mM PA', '0.50 mM PA', '1.00 mM PA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block for making a Pandas dataframe suitable for plotting violin plots.\n",
    "master_df = pd.DataFrame()\n",
    "counter = 0\n",
    "for condition in conditions:\n",
    "    for movie in condition_msds[condition]:\n",
    "        for channel in range(0, len(movie)):\n",
    "            master_df = master_df.append(append_condition(movie[channel], \n",
    "                                                          conditions_1[counter], \n",
    "                                                          channel))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional code block for seeing the MSDs in natural log scale\n",
    "log_dc = list()\n",
    "for index, row in master_df.iterrows():\n",
    "    log_dc.append(np.log(row['Diff_const']))\n",
    "master_df['log_DC'] = log_dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a violin plot that splits into red or green channels\n",
    "ax = sns.violinplot(x = 'Condition', \n",
    "                    y = 'Diff_const', data = master_df,\n",
    "                    hue = master_df.Channel, split = True, cut = 0,\n",
    "                   palette=['green', 'red'])\n",
    "ax.set_title('Diffusion Constants of IRE1 Molecules in CL-VB-69.4 Cells')\n",
    "ax.set_ylabel('Diffusion Constant')\n",
    "ax.set_xlabel('Conditions')\n",
    "ax.axhline(0.1, linestyle = '--', color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differences across conditions, regardless of spot channel\n",
    "\n",
    "fig2 = plt.figure()\n",
    "\n",
    "ax = sns.violinplot(x = 'Condition', \n",
    "                    y = 'Diff_const', data = master_df, cut = 0, color = 'steelblue')\n",
    "ax.set_title('MSD of Correlated Tracks in Green Channel')\n",
    "ax.set_ylabel('Diffusion Constant')\n",
    "ax.set_xlabel('Conditions')\n",
    "ax.axhline(0.1, linestyle = '--', color = 'black')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-do: write a script somewhere that can output filtered TrackMate files depending on some minimal or maximal value of MSD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
