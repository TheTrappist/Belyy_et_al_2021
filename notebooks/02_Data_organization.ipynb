{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to cleanly organize single-molecule tracking data by scanning through JSON parameter files used to generate figures and moving all XML TrackMate files into a specified folder, re-creating the JSON parameter file if needed. Optionally, it can also scan through the raw data file folder and move/organize all relevant raw data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined parameters\n",
    "\n",
    "# str or list of str:\n",
    "settings_files = ['../analysis_settings/Fig2F_HaloTagControls.json',\n",
    "                '../analysis_settings/Fig3F_IRE1-HaloTag.json',\n",
    "                '../analysis_settings/Fig4A_Tm_Tg_DTT.json',\n",
    "                '../analysis_settings/Fig4B_IRE1mutants.json',\n",
    "                '../analysis_settings/FigS1B_GST_dimer.json',\n",
    "                '../analysis_settings/FigS2_ERstress_HaloControls.json',\n",
    "                '../analysis_settings/FigS3D_IRE1-HaloTag_clones.json',\n",
    "                '../analysis_settings/FigS4_Trajectory_density.json']\n",
    "\n",
    "# Specify which data to organize (TrackMate outputs, raw data, or both)\n",
    "#organize_tracks = True\n",
    "organize_raw = True\n",
    "\n",
    "# Specify source directories\n",
    "# Reference directory to the relative paths in the settings JSON file(s)\n",
    "base_dir_tracks = r'/Volumes/Vlad Expansion 1/Data/Analysis_data_backups/IRE1_SPT/IRE1_cluster_analysis/data/processed/01_Analysis_settings/Good_analysis_settings'\n",
    "# Directory in which all raw image files are found (subdirectories OK)\n",
    "base_dir_raw = r'/Volumes/Vlad Expansion 1/Data/Analysis_data_backups/IRE1_SPT/IRE1_cluster_analysis/data/raw'\n",
    "\n",
    "#Specify target directories (absolute or relative to the notebook file)\n",
    "final_dir_tracks = '/Volumes/Vlad Expansion 1/Data/Data_for_manuscripts/Belyy_2021/tracks/processed'\n",
    "final_dir_json = '/Volumes/Vlad Expansion 1/Data/Data_for_manuscripts/Belyy_2021/tracks/analysis_settings'\n",
    "final_dir_raw = '/Volumes/Vlad Expansion 1/Data/Data_for_manuscripts/Belyy_2021/tracks/raw'\n",
    "\n",
    "image_file_extension = 'tif' # for searching through image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import json, os, copy, shutil, glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Uncomment the following two lines for debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add source code directory (src) to path to enable user module import\n",
    "module_dir = '../src'\n",
    "os.sys.path.insert(0, module_dir)\n",
    "\n",
    "# Import user modules from source code directory\n",
    "#import parse_trackmate as pt\n",
    "import correlation_analysis as corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and organize data\n",
    "\n",
    "\n",
    "if type(settings_files) is not list: settings_files = [settings_files]\n",
    "\n",
    "raw_files_copied = [] # to avoid duplicating raw files\n",
    "\n",
    "for file in settings_files:\n",
    "    print('Working on file: '+str(file))\n",
    "    conditions, params = corr.read_analysis_params(file, print_summary=False)\n",
    "    new_json = copy.deepcopy(params['raw_json'])\n",
    "    origin_paths = []\n",
    "    dest_paths = []\n",
    "    for condition, paths in params['raw_json']['conditions'].items():\n",
    "        if type(paths) is not list: paths = [paths]\n",
    "        new_paths_rel = []\n",
    "        for curr_path in paths:\n",
    "            path = Path(curr_path)\n",
    "            origin = (Path(base_dir_tracks) / path).resolve()\n",
    "            origin_paths.append(origin)\n",
    "            \n",
    "            #Keep folder and parent folder\n",
    "            dest_subfolder = origin.relative_to(origin.parents[1])\n",
    "            dest = (Path(final_dir_tracks) / dest_subfolder).resolve()\n",
    "            dest_paths.append(dest)\n",
    "            \n",
    "            #Determine relative path to put in the new JSON file\n",
    "            json_relpath = Path(os.path.relpath(dest,final_dir_json))\n",
    "            new_paths_rel.append(json_relpath.as_posix())\n",
    "            \n",
    "        new_json['conditions'][condition] = new_paths_rel\n",
    "        \n",
    "    # Move the xml and raw files without overwriting\n",
    "    num_dirs = len(origin_paths)\n",
    "    dir_counter = 1\n",
    "    for origin, dest in zip(origin_paths, dest_paths):\n",
    "        print('Working on directory '+str(dir_counter)+' out of '+str(num_dirs))\n",
    "        print(str(origin))\n",
    "        dir_counter = dir_counter + 1\n",
    "        if not os.path.exists(dest): os.makedirs(dest)\n",
    "        xml_files_in_origin = glob.glob(os.path.join(origin, '**/*.xml'), recursive=True)    \n",
    "        if not xml_files_in_origin:\n",
    "            print(\"WARNING: no valid xml files found in this directory!\")\n",
    "        else: print(str(len(xml_files_in_origin))+' xml files found here.')\n",
    "        for file_origin in xml_files_in_origin:\n",
    "            name = os.path.split(file_origin)[1]\n",
    "            file_dest = os.path.join(dest, name)\n",
    "            \n",
    "            # Move xml track files\n",
    "            if not os.path.exists(file_dest):\n",
    "                shutil.copy(file_origin, dest)\n",
    "            \n",
    "            # Locate and move raw tif files if needed\n",
    "            if organize_raw:\n",
    "                # get source file name\n",
    "                name_core = name[3:-4] # remove channel and extension\n",
    "                search_string = '*'+name_core+'.'+image_file_extension\n",
    "                # Look for matching tif file\n",
    "                source_path = list(Path(base_dir_raw).rglob(search_string))\n",
    "                if len(source_path) > 1:\n",
    "                    print('Too many matches found! Problematic files:')\n",
    "                    print(name_core)\n",
    "                    for x in source_path: print(x)\n",
    "                if len(source_path) == 0:\n",
    "                    print('No matches found! Problematic file:')\n",
    "                    print(name_core)\n",
    "                    continue\n",
    "                    \n",
    "                source_path = source_path[0]\n",
    "                \n",
    "                if source_path in raw_files_copied:\n",
    "                    continue # this file had already been moved\n",
    "                raw_files_copied.append(source_path)\n",
    "                \n",
    "                #Organize folder and parent folder to match those of the xml file\n",
    "                dest_subfolder = dest.relative_to(dest.parents[1])\n",
    "                dest_folder = os.path.join(final_dir_raw, dest_subfolder)\n",
    "                dest_folder = os.path.abspath(dest_folder)\n",
    "                if not os.path.exists(dest_folder): os.makedirs(dest_folder)\n",
    "                dest_file = os.path.join(dest_folder, os.path.split(source_path)[1])\n",
    "                # Move files to new folder without overwriting\n",
    "                if not os.path.exists(dest_file):\n",
    "                    shutil.copy(source_path, dest_file)\n",
    "        \n",
    "                \n",
    "    # write new JSON settings file\n",
    "    if not os.path.exists(final_dir_json): os.makedirs(final_dir_json)\n",
    "    json_file_name = os.path.split(file)[1]\n",
    "    json_file_path = os.path.join(final_dir_json, json_file_name)\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(new_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#print(params['raw_json'])\n",
    "#print(origin_paths)\n",
    "#print(dest_paths)\n",
    "#print(new_json['conditions'])\n",
    "    \n",
    "print('Job done')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
