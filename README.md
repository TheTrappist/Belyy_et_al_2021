# Correlation analysis in two-color single-molecule data

This repository is a collection of image analysis tools for our 2021 paper
on single-particle analysis of IRE1 stoichiometry. Every plot in the paper can
be reproduced with the included code, and this readme file contains step-by-step
instructions for doing so. Broadly, analysis is split into two parts:
1) Primary image analysis in ImageJ with scripted calls to the TrackMate plugin.
This step parses the 2-color TIFF movie files and creates lists of particle
trajectories in every movie for each of the two channels.
2) Secondary analysis of the processed data in Python (using Jupyter notebooks).
   This is the step that performs correlation analysis generates all the final
   plots/statistics.

### Software versions used
The code has been explicitly tested with the software versions indicated below.
Additionally, a YAML file containing the Conda python environment is provided
in the root folder of the repository, titled "SPT_analysis_conda_env.yml".

- Operating systems: tested on macOS High Sierra and MS Windows 10.
- Python: Version 3.7.4 (Anaconda dist.). https://www.anaconda.com/distribution/
- Seaborn (for data visualization): Version 0.9.0. https://seaborn.pydata.org/
- ImageJ: Version 1.53c (Fiji distribution). https://fiji.sc/
- TrackMate ImageJ plugin: Version 6.0.2. https://imagej.net/TrackMate/

### Project organization
The repository is organized into the following top-level folders:
1) data (all source data, in 'raw' and 'processed' subfolders, together with
  analysis settings in the "analysis_settings" subfolder)
2) imagej_scripts (all ImageJ scripts)
3) notebooks (Jupyter [IPython] notebooks)
4) reports (all output figures generated by the Jupyter notebook)
5) src (source Python files containing the bulk of the analysis functions)

### Detailed instructions for reproducing plots in individual figure panels
The plots can either be reproduced from raw movies (which involves a somewhat
time-consuming tracking step) or from TrackMate output files that we are
providing alongside the raw movies.

A. If starting from raw movies:
1) Download the original TIFF files into the "data/raw" subfolder of the
  repository. Make sure to preserve their folder structure as folders are later
  used to determine which movies correspond to which experimental conditions.
2) From within FIJI/ImageJ, run the script "Run_2color_TrackMate_analysis.py".
  This script provides a wrapper for the TrackMate ImageJ plugin and carries out
  batch tracking of both channels in all two-color movies in a given directory.
3) In the dialog box that opens when you run the script, set "Directory for
  source files" to the folder where you just downloaded raw movies. "Directory
  to save TrackMate output to" should be set to "data/processed". "File types"
  should be set to tif, and both "Recursive search" and "Preserve subdirectory
  structure" should remain checked. Finally, choose any name for the output
  settings file, and point "Input settings file" to a JSON file containing
  tracking settings. I am including one such file as an example in
  "data/analysis_settings/TrackMate_settings.json_EXAMPLE" (make sure to remove
  "_EXAMPLE" from the extension to make it a regular JSON file). This example
  file contains tracking settings that were used for every movie in this
  manuscript.
4) Run the script after all settings have been set as indicated. This will take
  some time; go grab a coffee and enjoy a jog or a bike ride.
5) When the script finishes, you will have populated the "data/processed" folder
  with TrackMate XML files (one per channel, so two XML files for every movie)
  in a folder structure that mirrors that of the TIFF raw data files. You are
  now ready to run correlation analysis.

B. If starting from tracks (or after finishing tracking as described above)
1) Place all TrackMate XML track files into the "data/processed" subfolder,
  making sure to preserve their subdirectory structure.
2) Open the Jupyter notebook "01_SPT_stoichiometry_analysis.ipynb".
3) In the first code cell, set the "settings_file" to the location of the JSON
  settings file containing the settings for the figure you are looking to
  reproduce (I am providing settings files for each of the figures together with
  the data; just make sure that the settings file is in the
  "data/analysis_settings/" subfolder so that relative paths work correctly).
4) Alternatively, you can create your own settings file by modifying the example
  file provided in "data/analysis_settings/
  Correlation_analysis_settings.json_EXAMPLE" (remove "_EXAMPLE" from the end).
  The organizatin of the JSON settings files is self-explanatory. First, the
  experimental conditions are listed as a dictionary, with condition name as the
  key and all subfolders containing XML TrackMate files corresponding to that
  condition stored in a list. Relative paths are allowed and encouraged. Then,
  analysis parameters follow, with desired directory names for saving data
  and filtered trajectories. The final two items are "window" and "pcc_cutoff",
  which determine the length of the window in frames and the stringency of
  correlation coefficient required to determine that two tracks are correlated.
5) If you like, you can change the other settings in the user-definted parameter
  box of the Jupyter notebook, but this should not be necessary.
6) Run the notebook and wait for it to show you figures. You're done!

### Notes
- The script "plotting_settings.py" in the "src" folder is called at the
beginning of the Jupyter notebook to set a uniform plot style. Feel free to make
changes to this file to modify all your plots in a consistent manner.
- The second Jupyter notebook, "02_Data_organization.ipynb", was more of an
internal tool that I'm including in this repository in case it can be of help to
someone. It combs through existing JSON settings files and moves only the XML
files that are called in those files into a new folder (also, optionally,
locating and moving the corresponding raw TIFF files). This is useful when you
have a huge amount of tracking data in one place and need to copy or back up
only data that you're using for a specific round of analysis, such as when
preparing all data associated with a publication.
- I have attempted to make the code reasonably well-documented and organized. It
is my hope that a basic working knowledge of Python and Pandas (which is
included in the Anaconda distribution) will allow you to quickly start making
changes to make the analysis fit your specific needs.
- If you find errors in the code or write additional code that you think would
be useful to contribute to this repository, either raise an issue on Github or
contact me on the Image.sc forum (https://forum.image.sc/). I will do my best to
respond as quickly as possible. My username on both resources is "TheTrappist".

Thank you, and hope this helps!
Vladislav (Vlad) Belyy
